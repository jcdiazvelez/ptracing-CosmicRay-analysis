import numpy as np
import healpy as hp
import matplotlib.pyplot as plt
from scipy.stats import poisson, norm
import random
import scipy.stats 
from tqdm import tqdm

# Probability density function for power law functions
def powerlaw_pdf(x, x_min, x_max, power):
    x_min_g, x_max_g = x_min ** (power + 1.), x_max ** (power + 1.)
    if power == -1.0:
        return x ** power / np.log(x_max / x_min)
    else:
        return (power + 1.) / (x_max_g - x_min_g) * x ** power

# Weighting scheme for energy bins
def weight_powerlaw(x, x_min, x_max, g, power):
    return x ** g / powerlaw_pdf(x, x_min, x_max, power)

def generate_log_uniform_data(low, high, sample_size):
    if low <= 0:
        raise ValueError("low limit must be higher than 0")
    log_low = np.log10(low)
    log_high = np.log10(high)
    log_data = np.random.uniform(log_low, log_high, sample_size)
    data = np.power(10, log_data)
    return data

def generate_normal_weights(mean, std_dev, sample_size):
    weights = np.random.normal(mean, std_dev, sample_size)
    return (weights - np.min(weights)) / (np.max(weights) - np.min(weights)) if np.max(weights) > np.min(weights) else weights

def hist_plot(edges, Wi_on, Wi_off, S2i_on, S2i_off):
    plt.figure(figsize=(10, 6))
    plt.errorbar(edges[1:], Wi_on, yerr=np.sqrt(S2i_on))
    plt.errorbar(edges[1:], Wi_off, yerr=np.sqrt(S2i_off))
    plt.title('Error Wi_on vs Wi_off')
    plt.xlabel('Value')
    plt.ylabel('Error')
    plt.xscale('log')
    plt.yscale('log')
    plt.legend()
    plt.grid(True)
    plt.show()

def chi2_pdf_plot(chi2_concat):
    xbins = np.logspace(-2, 3, 100)
    hist, edges = np.histogram(chi2_concat, bins=xbins, density=True)
    rv = scipy.stats.chi2(20)
    plt.figure(figsize=(10, 6))
    plt.plot(xbins, rv.pdf(xbins), 'k-', lw=2, label='pdf (20 dof)')
    plt.plot(edges[1:], hist, label = 'data')
    plt.yscale('log')
    plt.xscale('log')
    plt.title('Chi2 PDF')
    plt.xlabel('Bins')
    plt.ylabel('Frequency')
    plt.legend()
    plt.grid(True)
    plt.show()    

def test_weights_v3(data1, data2, wei1, wei2):
    min_val = min(np.min(data1), np.min(data2))
    max_val = max(np.max(data1), np.max(data2))
    bins_count = 21

    if min_val <= 0:
        min_val = 1e-10  # Small positive value

    ebins = np.logspace(np.log10(min_val), np.log10(max_val), bins_count)

    # Normalize weights
    norm1 = np.sum(wei1)
    norm2 = np.sum(wei2)
    wei1_norm = wei1 / norm1
    wei2_norm = wei2 / norm2

    # Histogram
    Wi_on, edges = np.histogram(data1, bins=ebins, weights=wei1_norm)
    S2i_on, _ = np.histogram(data1, bins=ebins, weights=np.power(wei1_norm, 2))
    Wi_off, _ = np.histogram(data2, bins=ebins, weights=wei2_norm)
    S2i_off, _ = np.histogram(data2, bins=ebins, weights=np.power(wei2_norm, 2))

    # Plots on/off histograms per pixel
    hist_plot(edges, Wi_on, Wi_off, S2i_on, S2i_off)

    valid_Wi_on = Wi_on > 0
    valid_Wi_off = Wi_off > 0
    di2 = np.zeros_like(Wi_off, dtype=np.float64)
    di2[valid_Wi_on & valid_Wi_off] = Wi_off[valid_Wi_on & valid_Wi_off] * (
        S2i_on[valid_Wi_on & valid_Wi_off] / Wi_on[valid_Wi_on & valid_Wi_off] + 
        S2i_off[valid_Wi_on & valid_Wi_off] / Wi_off[valid_Wi_on & valid_Wi_off])
    di2[~(valid_Wi_on & valid_Wi_off)] = np.inf

    # Chi2 calculation
    chi2 = np.sum(np.power((Wi_on - Wi_off), 2) / di2)
    return chi2

def generic_chi2_test(sample_size, low, high):
    # Generate an array with random normal distributions at the boundary layer
    ext_boundary_dist = []
    for _ in range(sample_size):
        energies = generate_log_uniform_data(low, high, sample_size)
        #weights = generate_normal_weights(mean3, std_dev3, sample_size)
        weights = weight_powerlaw(energies, low, high, -2.6, -1)
        ext_boundary_dist.append([energies, weights])

    # Randomly map the boundary distribution array to the inner boundary
    int_boundary_dist = ext_boundary_dist.copy()

    random.shuffle(int_boundary_dist)

    # Calculate chi2
    chi2_concat = []
    for i in range(sample_size):
        data1 = int_boundary_dist[i][0]  # energy values from shuffled list
        wei1 = int_boundary_dist[i][1]  # weight values from shuffled list

        # Select a random index for data2 and wei2
        random_index = np.random.randint(sample_size)
        data2 = int_boundary_dist[random_index][0]  # energy values at random index
        wei2 = int_boundary_dist[random_index][1]  # corresponding weight values at random index

        chi2 = test_weights_v3(data1, data2, wei1, wei2)
        chi2_concat.append(chi2)
    return chi2_concat

#&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&CHI2 GENERIC TEST&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&#
# Global parameters
sample_size = 5000

# Parameters for Uniform data
low = 5.287760354365922
high = 14.985871050425096

# Parameters for NOrmal data
mean3 = 1.0
std_dev3 = 0.5
mean4 = 1.0
std_dev4 = 0.5

# Plot chi2 calculation vs chi2 pdf
# chi2_pdf_plot(generic_chi2_test(sample_size, low, high))
#&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&#
#&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&#
#&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&#

# PARTICLE TESTING #

#&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&#
#&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&#
#&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&#
def get_pixel_distribution(pixel):
    energies = [particle[0] for particle in pixel]
    weights = [particle[1] for particle in pixel]
    return np.array([energies, weights])

def get_sky_distribution(pixel_list):
    energies = []
    weights = []
    for pixel in pixel_list:
        distribution = get_pixel_distribution(pixel)
        energies += distribution[0].tolist()
        weights += distribution[1].tolist()
    return np.array([energies, weights])

def get_strip_distribution(pixel_number, pixel_list, nside, num_pixels):
    theta, phi = hp.pix2ang(nside, pixel_number)
    vec = hp.pix2vec(nside, pixel_number)
    d_theta = np.sqrt(hp.nside2pixarea(nside))
    strip = hp.query_strip(nside, theta - num_pixels * d_theta, theta + num_pixels * d_theta)
    particle_ring = hp.query_disc(nside, vec, num_pixels * d_theta)
    strip = np.setdiff1d(strip, particle_ring)
    return get_sky_distribution(pixel_list[strip]), len(strip)

def get_ring_distribution(pixel_number, pixel_list, nside, num_pixels):
    vec = hp.pix2vec(nside, pixel_number)
    d_theta = np.sqrt(hp.nside2pixarea(nside))
    particle_ring = hp.query_disc(nside, vec, num_pixels * d_theta)
    return get_sky_distribution(pixel_list[particle_ring]), len(particle_ring)

def impose_energy_range(distribution, min_energy, max_energy):
    energies = distribution[0]
    weights = distribution[1]
    indices = np.where(np.logical_and(energies >= min_energy, energies <= max_energy))
    return np.array([energies[indices], weights[indices]])

def perform_test_weights_v3(particles, limits, width):
    # Physical constants for scaling momentum
    c = 299792458
    e = 1.60217663 * 10 ** (-19)
    m_p = 1.67262192 * 10 ** (-27)
    npix = len(particles)
    nside = hp.npix2nside(npix)
    lower = limits[0] / (m_p * c * c / (e * 10 ** 12))
    upper = limits[1] / (m_p * c * c / (e * 10 ** 12))

    chi2sum = []
    for i in tqdm(range(npix)):
        strip_distribution, _ = get_strip_distribution(i, particles, nside, width)
        strip_distribution = impose_energy_range(strip_distribution, lower, upper)
        pixel_distribution, _ = get_ring_distribution(i, particles, nside, width)
        pixel_distribution = impose_energy_range(pixel_distribution, lower, upper)
        chi2 = test_weights_v3(pixel_distribution[0], strip_distribution[0],
                              pixel_distribution[1], strip_distribution[1])
        chi2sum.append(chi2)
    return chi2sum

def generic_shuffle_test(particles, limits, width):
    # Physical constants for scaling momentum
    c = 299792458
    e = 1.60217663 * 10 ** (-19)
    m_p = 1.67262192 * 10 ** (-27)
    npix = len(particles)
    nside = hp.npix2nside(npix)
    lower = limits[0] / (m_p * c * c / (e * 10 ** 12))
    upper = limits[1] / (m_p * c * c / (e * 10 ** 12))

    ext_boundary_dist = []
    for i in tqdm(range(npix)):
        pixel_distribution, _ = get_ring_distribution(i, particles, nside, width)
        pixel_distribution = impose_energy_range(pixel_distribution, lower, upper)
        ext_boundary_dist.append([pixel_distribution[0], pixel_distribution[1]])

    # Randomly map the boundary distribution array to the inner boundary
    int_boundary_dist = ext_boundary_dist.copy()
    print('int_boundary_dist lenght', len(int_boundary_dist))

    random.shuffle(int_boundary_dist)
    print('IM HERE AFTER SHUFFLE')

    # Calculate chi2
    chi2_concat = []
    for i in range(npix):
        data1 = int_boundary_dist[i][0]  # energy values from shuffled list
        wei1 = int_boundary_dist[i][1]  # weight values from shuffled list

        # Select a random index for data2 and wei2
        random_index = np.random.randint(npix)
        data2 = int_boundary_dist[random_index][0]  # energy values at random index
        wei2 = int_boundary_dist[random_index][1]  # corresponding weight values at random index

        chi2 = test_weights_v3(data1, data2, wei1, wei2)
        chi2_concat.append(chi2)
    return chi2_concat

def load_npz_file_as_ndarray(file_path):
    try:
        # Load the .npz file
        with np.load(file_path) as data:
            # Convert to a list of arrays
            arrays = [data[key] for key in data.files]
            # Stack arrays into a single NDArray
            particles = np.vstack(arrays)
        return particles

    except IOError as e:
        print(f"Error loading .npz file: {e}")
        return None

#&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&TEST PARTICLE DATA&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&#
particles_dir = "/home/aamarinp/Documents/ptracing-CosmicRay-analysis/data/particles/test_particles_phyindex_1_ext_bound.npz"
particles = load_npz_file_as_ndarray(particles_dir)
print('PARTICLES WERE SUCCESSFULLY LOADED')

# chi2_test = perform_test_weights_v3(particles, [0.1, 200], 5)
generic_shuffle_test(particles, [0.1, 200], 5)

